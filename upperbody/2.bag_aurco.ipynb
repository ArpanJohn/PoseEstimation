{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "import pyrealsense2 as rs\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os.path\n",
    "import mediapipe as mp\n",
    "import time\n",
    "import os\n",
    "import cv2.aruco as aruco\n",
    "\n",
    "h=720\n",
    "w=1280\n",
    "windowscale=0.6\n",
    "\n",
    "pc = rs.pointcloud()\n",
    "\n",
    "fps=30\n",
    "try:\n",
    "    # Create pipeline\n",
    "    pipeline = rs.pipeline()\n",
    "\n",
    "    # Create a config object\n",
    "    config = rs.config()\n",
    "\n",
    "    # Tell config that we will use a recorded device from file to be used by the pipeline through playback.\n",
    "    rs.config.enable_device_from_file(config, r'C:\\Users\\arpan\\OneDrive\\Documents\\internship\\bags\\gpane.bag', repeat_playback=False)\n",
    "\n",
    "    # Configure the pipeline to stream the depth stream\n",
    "    # Change this parameters according to the recorded bag file resolution\n",
    "    config.enable_stream(rs.stream.depth, rs.format.z16, fps)\n",
    "    config.enable_stream(rs.stream.color, rs.format.rgb8, fps)\n",
    "\n",
    "    # Start streaming from file\n",
    "    profile=pipeline.start(config)\n",
    "    \n",
    "    # Create colorizer object\n",
    "    colorizer = rs.colorizer()\n",
    "\n",
    "    #Needed so frames don't get dropped during processing:\n",
    "    profile.get_device().as_playback().set_real_time(False)\n",
    "\n",
    "    align_to = rs.stream.color\n",
    "    align = rs.align(align_to)\n",
    "\n",
    "    timestamps=[]\n",
    "    \n",
    "    # Frame at which to find the L frame\n",
    "    calib_frame=50\n",
    "\n",
    "    # Frame counter\n",
    "    c=0\n",
    "\n",
    "    # Streaming loop\n",
    "    while True:\n",
    "\n",
    "        frame_present, frameset = pipeline.try_wait_for_frames()\n",
    "    \n",
    "        #End loop once video finishes\n",
    "        if not frame_present:\n",
    "            break\n",
    "\n",
    "        # Wait for a coherent pair of frames: depth and color\n",
    "        frames = pipeline.wait_for_frames()\n",
    "        aligned_frames = align.process(frames)\n",
    "        depth_frame = frames.get_depth_frame()\n",
    "        color_frame = frames.get_color_frame()\n",
    "        if not depth_frame or not color_frame:\n",
    "            continue\n",
    "        \n",
    "        # get timestamp of frame\n",
    "        timestamps.append(rs.frame.get_frame_metadata(depth_frame,rs.frame_metadata_value.time_of_arrival))\n",
    "\n",
    "        # Get aligned frames\n",
    "        aligned_depth_frame = aligned_frames.get_depth_frame() \n",
    "        color_frame = aligned_frames.get_color_frame()\n",
    "\n",
    "        # Convert images to numpy arrays\n",
    "        depth_image = np.asanyarray(aligned_depth_frame.get_data()) \n",
    "        color_image = np.asanyarray(color_frame.get_data()) \n",
    "\n",
    "        #converting color image to BGR\n",
    "        color_image = cv2.cvtColor(color_image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        # Apply colormap on depth image (image must be converted to 8-bit per pixel first)\n",
    "        depth_colormap = cv2.applyColorMap(cv2.convertScaleAbs(depth_image, alpha=0.03), cv2.COLORMAP_JET)\n",
    "\n",
    "        depth_colormap_dim = depth_colormap.shape\n",
    "        color_colormap_dim = color_image.shape\n",
    "\n",
    "        # If depth and color resolutions are different, resize color image to match depth image for display\n",
    "        if depth_colormap_dim != color_colormap_dim:\n",
    "            resized_color_image = cv2.resize(color_image, dsize=(depth_colormap_dim[1], depth_colormap_dim[0]), interpolation=cv2.INTER_AREA)\n",
    "            images = np.hstack((resized_color_image, depth_colormap))\n",
    "        else:\n",
    "            images =np.hstack((color_image, depth_colormap))\n",
    "\n",
    "        \n",
    "        # When calibration frame is reached find the 3D position data and save it in xyzpos\n",
    "        if c==calib_frame:\n",
    "            mapped_frame = color_frame\n",
    "            pc.map_to(mapped_frame)\n",
    "            \n",
    "            try:\n",
    "                points = pc.calculate(aligned_depth_frame)\n",
    "                v = points.get_vertices()\n",
    "                verts = np.asanyarray(v).view(np.float32)\n",
    "                xyzpos=verts.reshape(h,w, 3)  # xyz     \n",
    "            except:\n",
    "                print(type(v))\n",
    "            break\n",
    "        # print(c)\n",
    "        c+=1\n",
    "\n",
    "finally:\n",
    "    # Specify the ArUco dictionary\n",
    "    aruco_dict = aruco.getPredefinedDictionary(aruco.DICT_ARUCO_ORIGINAL)\n",
    "\n",
    "    # Create the parameters for the ArUco detector\n",
    "    parameters = aruco.DetectorParameters_create()\n",
    "\n",
    "    # Detect the ArUco markers in the image\n",
    "    corners, ids, _ = aruco.detectMarkers(color_image, aruco_dict, parameters=parameters)\n",
    "\n",
    "    for corner in corners:\n",
    "            center = np.mean(corner[0], axis=0)\n",
    "            x = int(center[0])\n",
    "            y = int(center[1])\n",
    "            # cv2.circle(color_image, (x, y), 50, (0, 255, 0), 2)\n",
    "\n",
    "    # Draw a circle around the center of each detected marker\n",
    "    centers=[]\n",
    "    for corner in corners:\n",
    "            center = np.mean(corner[0], axis=0)\n",
    "            x = int(center[0])\n",
    "            y = int(center[1])\n",
    "            centers.append((x,y))\n",
    "            # cv2.circle(color_image, (x, y), 50, (0, 255, 0), 2)\n",
    "\n",
    "    cv2.circle(color_image, (centers[0][0],centers[0][1]), 30, (255, 0, 0), 4) #blue \n",
    "    cv2.circle(color_image, (centers[1][0],centers[1][1]), 30, (0, 255, 0), 4) #green\n",
    "    cv2.circle(color_image, (centers[2][0],centers[2][1]), 30, (0, 0, 255), 4) #red\n",
    "    cv2.imshow(\"show\", color_image)\n",
    "\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        pass\n",
    "    try:\n",
    "        if (color_image)==-1:\n",
    "            cv2.destroyAllWindows()\n",
    "            pass\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    cv2.waitKey(0)\n",
    "    # Show images\n",
    "    cv2.namedWindow('RealSense', cv2.WINDOW_AUTOSIZE)\n",
    "    cv2.imshow('RealSense', color_image)\n",
    "    if cv2.waitKey(5) & 0xFF == ord('q'):\n",
    "        pass\n",
    "\n",
    "    # Stop streaming\n",
    "    pipeline.stop()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Centers assigned\n"
     ]
    }
   ],
   "source": [
    "# Assigning centers to origin, x axis and z axis\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        if i!=j:\n",
    "            if 19<np.linalg.norm(xyzpos[centers[i][1],centers[i][0]]-xyzpos[centers[j][1],centers[j][0]])*100<21 and 14<np.linalg.norm(xyzpos[centers[3-(j+i)][1],centers[3-(j+i)][0]]-xyzpos[centers[j][1],centers[j][0]])*100<16:\n",
    "                cento=xyzpos[centers[j][1],centers[j][0]]\n",
    "                centz=xyzpos[centers[i][1],centers[i][0]]\n",
    "                centx=xyzpos[centers[3-(j+i)][1],centers[3-(j+i)][0]]\n",
    "                print('Centers assigned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.006002\n",
      "14.814707\n"
     ]
    }
   ],
   "source": [
    "#verifiying centers\n",
    "org_z=np.add(centz,-cento)*100\n",
    "org_x=np.add(cento,-centx)*100\n",
    "print(np.linalg.norm(org_z))\n",
    "print(np.linalg.norm(org_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.9999033  -0.00333314 -0.01349992]\n",
      "[-0.00257728  0.02846707 -0.19792107]\n",
      "[-0.01288807  0.14235358 -0.9897319 ]\n",
      "[[-0.00522068]\n",
      " [-0.9898102 ]\n",
      " [-0.14229685]]\n",
      "0.99999994\n"
     ]
    }
   ],
   "source": [
    "# Finding the Rotation matrix\n",
    "v1 = centx - cento  # v1\n",
    "v2 = centz - cento  # v2\n",
    "\n",
    "vxnorm = v1 / np.linalg.norm(v1)\n",
    "print(vxnorm)\n",
    "vzcap = v2 - (vxnorm.T @ v2) * vxnorm\n",
    "print(vzcap)\n",
    "vznorm = vzcap / np.linalg.norm(vzcap)\n",
    "print(vznorm)\n",
    "\n",
    "vynorm=np.cross(vznorm.T,vxnorm.T).reshape(3,1)\n",
    "print(vynorm)\n",
    "\n",
    "print(np.linalg.norm(vynorm))\n",
    "\n",
    "vznorm=vznorm.reshape(3,1)\n",
    "vxnorm=vxnorm.reshape(3,1)\n",
    "\n",
    "rotMat = np.hstack((vxnorm, vynorm, vznorm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.9999033  -0.00522068 -0.01288807]\n",
      " [-0.00333314 -0.9898102   0.14235358]\n",
      " [-0.01349992 -0.14229685 -0.9897319 ]]\n",
      "[0.13313153 0.33307818 1.3490001 ]\n"
     ]
    }
   ],
   "source": [
    "print(rotMat)\n",
    "print(cento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the roation Matrix and the origin to files\n",
    "with open(r'D435_rotmat.txt', 'w') as fp:\n",
    "    for item in rotMat:\n",
    "        # write each item on a new line\n",
    "        fp.write(\"%s\\n\" % item)\n",
    "\n",
    "with open(r'D435_org.txt', 'w') as fp:\n",
    "    for item in cento:\n",
    "        # write each item on a new line\n",
    "        fp.write(\"%s\\n\" % item)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
